"""
batch.py - æ‰¹é‡ç‰¹å¾æå–å’Œæäº¤æ–‡ä»¶ç”Ÿæˆ

ä½œç”¨ï¼š
    ä½¿ç”¨ DataLoader æ‰¹é‡å¤„ç†æµ‹è¯•å›¾ç‰‡ï¼Œæ¯” test.py å¿« 3-5 å€

ä½•æ—¶ä½¿ç”¨ï¼š
    1. è®­ç»ƒå®Œæˆåï¼Œç”Ÿæˆæœ€ç»ˆçš„ submission.csv
    2. å½“æµ‹è¯•å›¾ç‰‡æ•°é‡å¤§ï¼ˆ371å¼ ï¼‰æ—¶ï¼Œæ‰¹å¤„ç†æ›´é«˜æ•ˆ

ä¸ test.py çš„åŒºåˆ«ï¼š
    - test.py: é€å¼ å¤„ç†ï¼Œä»£ç ç®€å•ï¼Œé€‚åˆè°ƒè¯•
    - batch.py: æ‰¹é‡å¤„ç†ï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆæœ€ç»ˆæäº¤

ç”¨æ³•ï¼š
    python batch.py --model_path checkpoints/best_model.pth --data_dir /path/to/data --output submission.csv
"""

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import pandas as pd
import numpy as np
from PIL import Image
from pathlib import Path
from tqdm import tqdm
import argparse
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from model import ViTForJaguarReID, MegaDescriptorWrapper
from torchvision import transforms


class TestJaguarDataset(Dataset):
    """æµ‹è¯•é›†æ•°æ®é›†"""

    def __init__(self, image_dir, transform=None):
        self.image_dir = Path(image_dir)
        self.image_files = sorted(
            [f for f in self.image_dir.iterdir()
             if f.suffix.lower() in ['.jpg', '.png', '.jpeg']])
        self.transform = transform
        self.image_names = [f.name for f in self.image_files]

        print(f"åŠ è½½æµ‹è¯•å›¾ç‰‡: {len(self.image_files)} å¼ ")

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, self.image_names[idx]


def batch_extract_features(model, test_loader, device):
    """
    æ‰¹é‡æå–æ‰€æœ‰æµ‹è¯•å›¾ç‰‡çš„ç‰¹å¾

    Returns:
        features_dict: {å›¾ç‰‡å: ç‰¹å¾å‘é‡}
    """
    model.eval()
    features_dict = {}

    with torch.no_grad():
        for images, names in tqdm(test_loader, desc="æ‰¹é‡æå–ç‰¹å¾"):
            images = images.to(device, non_blocking=True)

            # æå–ç‰¹å¾
            features = model(images, return_features=True)

            # L2 å½’ä¸€åŒ–ï¼ˆå¯¹äºä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé‡è¦ï¼‰
            features = F.normalize(features, p=2, dim=1)

            for i, name in enumerate(names):
                features_dict[name] = features[i].cpu().numpy()

    return features_dict


def compute_all_similarities(features_dict, test_df):
    """
    è®¡ç®—æ‰€æœ‰å›¾ç‰‡å¯¹çš„ç›¸ä¼¼åº¦

    Args:
        features_dict: {å›¾ç‰‡å: ç‰¹å¾å‘é‡}
        test_df: åŒ…å« query_image, gallery_image çš„ DataFrame

    Returns:
        similarities: ç›¸ä¼¼åº¦åˆ—è¡¨
    """
    similarities = []

    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc="è®¡ç®—ç›¸ä¼¼åº¦"):
        query = row['query_image']
        gallery = row['gallery_image']

        if query in features_dict and gallery in features_dict:
            feat1 = torch.from_numpy(features_dict[query])
            feat2 = torch.from_numpy(features_dict[gallery])

            # ä½™å¼¦ç›¸ä¼¼åº¦ (å› ä¸ºå·²ç» L2 å½’ä¸€åŒ–ï¼Œç›´æ¥ç‚¹ç§¯å³å¯)
            similarity = torch.dot(feat1, feat2).item()

            # æ˜ å°„åˆ° [0, 1] èŒƒå›´ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦åŸæœ¬æ˜¯ [-1, 1]ï¼‰
            similarity = (similarity + 1) / 2

            # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
            similarity = max(0.0, min(1.0, similarity))
        else:
            print(f"è­¦å‘Š: ç¼ºå°‘ç‰¹å¾ - {query} æˆ– {gallery}")
            similarity = 0.5  # é»˜è®¤å€¼

        similarities.append(similarity)

    return similarities


def validate_submission(submission):
    """éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼"""
    errors = []

    if len(submission) != 137270:
        errors.append(f"è¡Œæ•°é”™è¯¯: {len(submission)}, åº”ä¸º 137270")

    if list(submission.columns) != ['row_id', 'similarity']:
        errors.append(f"åˆ—åé”™è¯¯: {list(submission.columns)}")

    if submission['row_id'].tolist() != list(range(137270)):
        errors.append("row_id é¡ºåºé”™è¯¯")

    if (submission['similarity'] < 0).any():
        errors.append(f"å­˜åœ¨ç›¸ä¼¼åº¦ < 0")

    if (submission['similarity'] > 1).any():
        errors.append(f"å­˜åœ¨ç›¸ä¼¼åº¦ > 1")

    if submission['similarity'].isna().any():
        errors.append(f"å­˜åœ¨ NaN å€¼")

    if errors:
        print("âŒ éªŒè¯å¤±è´¥:")
        for e in errors:
            print(f"   - {e}")
        return False
    else:
        print("âœ… æäº¤æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
        return True


def main():
    parser = argparse.ArgumentParser(description='Jaguar Re-ID æ‰¹é‡æ¨ç†')
    parser.add_argument('--model_path', type=str, default='checkpoints/best_model.pth',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--data_dir', type=str, required=True,
                        help='æ•°æ®ç›®å½• (åŒ…å« test.csv å’Œ test/ æ–‡ä»¶å¤¹)')
    parser.add_argument('--output', type=str, default='submission.csv',
                        help='è¾“å‡ºæ–‡ä»¶å')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ‰¹å¤§å°')
    args = parser.parse_args()

    # è®¾å¤‡é…ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")

    # åŠ è½½æ¨¡å‹
    print(f"\nåŠ è½½æ¨¡å‹: {args.model_path}")
    checkpoint = torch.load(args.model_path, map_location='cpu')
    num_classes = checkpoint.get('num_classes', 31)

    model = ViTForJaguarReID(num_classes=num_classes)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    print(f"æ¨¡å‹ç±»åˆ«æ•°: {num_classes}")

    # å›¾åƒå˜æ¢
    transform = transforms.Compose([
        transforms.Resize((384, 384)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å’ŒåŠ è½½å™¨
    test_dir = os.path.join(args.data_dir, 'test')
    test_dataset = TestJaguarDataset(test_dir, transform=transform)
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,  # ä¸æ‰“ä¹±é¡ºåº
        num_workers=4,
        pin_memory=True
    )

    # æ‰¹é‡æå–ç‰¹å¾
    print("\nå¼€å§‹æ‰¹é‡æå–ç‰¹å¾...")
    features_dict = batch_extract_features(model, test_loader, device)
    print(f"æå–å®Œæˆ: {len(features_dict)} å¼ å›¾ç‰‡")

    # åŠ è½½æµ‹è¯•å¯¹
    test_csv = os.path.join(args.data_dir, 'test.csv')
    test_df = pd.read_csv(test_csv)
    print(f"\næµ‹è¯•å¯¹æ•°: {len(test_df)}")

    # è®¡ç®—ç›¸ä¼¼åº¦
    print("\nè®¡ç®—æ‰€æœ‰å›¾ç‰‡å¯¹çš„ç›¸ä¼¼åº¦...")
    similarities = compute_all_similarities(features_dict, test_df)

    # åˆ›å»ºæäº¤æ–‡ä»¶
    submission = pd.DataFrame({
        'row_id': test_df['row_id'],
        'similarity': similarities
    })

    # éªŒè¯æ ¼å¼
    print("\néªŒè¯æäº¤æ–‡ä»¶æ ¼å¼...")
    validate_submission(submission)

    # ä¿å­˜
    submission.to_csv(args.output, index=False)

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nâœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {args.output}")
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»è¡Œæ•°: {len(submission)}")
    print(f"   ç›¸ä¼¼åº¦èŒƒå›´: [{submission['similarity'].min():.6f}, {submission['similarity'].max():.6f}]")
    print(f"   ç›¸ä¼¼åº¦å‡å€¼: {submission['similarity'].mean():.6f}")
    print(f"   ç›¸ä¼¼åº¦æ ‡å‡†å·®: {submission['similarity'].std():.6f}")

    # åˆ†å¸ƒä¿¡æ¯
    print(f"\nğŸ“ˆ ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
    bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]
    for i in range(len(bins) - 1):
        count = ((submission['similarity'] >= bins[i]) &
                 (submission['similarity'] < bins[i + 1])).sum()
        pct = count / len(submission) * 100
        print(f"   [{bins[i]:.1f}, {bins[i + 1]:.1f}): {count:,} ({pct:.1f}%)")


if __name__ == '__main__':
    main()